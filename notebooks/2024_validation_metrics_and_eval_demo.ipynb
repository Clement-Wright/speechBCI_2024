{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2024 Validation Metrics & Brain-to-Text 2025 Evaluation Demo\n",
        "\n",
        "This notebook summarizes the reproduction of the 2024 validation metrics\n",
        "using the archived prediction samples and walks through the new Kaggle-ready\n",
        "evaluation pipeline built around `eval_competition.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load archived predictions\n",
        "\n",
        "The `notebooks/samples/` directory contains the CIBR 2024 validation targets\n",
        "and two baseline model hypotheses. We parse them to compute character and\n",
        "word error rates using `jiwer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from jiwer import cer, wer\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    for candidate in (start,) + tuple(start.parents):\n",
        "        if (candidate / 'eval_competition.py').exists():\n",
        "            return candidate\n",
        "    raise RuntimeError('Could not locate repository root from ' + str(start))\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "SAMPLES_DIR = PROJECT_ROOT / 'notebooks' / 'samples'\n",
        "reference_path = SAMPLES_DIR / 'target_test.txt'\n",
        "model_paths = {\n",
        "    'Model 1 test': SAMPLES_DIR / 'model1_test.txt',\n",
        "    'Model 2 test': SAMPLES_DIR / 'model2_test.txt',\n",
        "}\n",
        "\n",
        "with reference_path.open() as handle:\n",
        "    references = [line.strip() for line in handle]\n",
        "\n",
        "metrics = []\n",
        "for name, pred_path in model_paths.items():\n",
        "    with pred_path.open() as handle:\n",
        "        predictions = [line.strip() for line in handle]\n",
        "    metrics.append({\n",
        "        'model': name,\n",
        "        'CER': cer(references, predictions),\n",
        "        'WER': wer(references, predictions),\n",
        "    })\n",
        "\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a Kaggle-formatted submission\n",
        "\n",
        "The helper `save_submission` function (defined in `eval_competition.py`) is\n",
        "now responsible for formatting predictions for the Brain-to-Text 2025\n",
        "competition. We reuse the 2024 validation references as example predictions\n",
        "to illustrate how `.csv` files and zipped archives are produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "from eval_competition import save_submission\n",
        "\n",
        "demo_dir = PROJECT_ROOT / 'notebooks' / 'samples' / 'demo_submission'\n",
        "submission_path, zip_path = save_submission(\n",
        "    predictions=references[:5],\n",
        "    output_dir=str(demo_dir),\n",
        "    submission_format='csv',\n",
        "    compress=True,\n",
        ")\n",
        "submission_path, zip_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the submission preview\n",
        "\n",
        "The `.csv` file uses the `id,text` schema required by Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission_path.read_text().splitlines()[:6]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}